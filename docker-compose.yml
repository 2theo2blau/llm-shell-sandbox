services:
  llm-shell:
    container_name: llm-shell
    build: .
    ports:
      - "${FLASK_PORT}:${FLASK_PORT}"
    env_file:
      - .env
    environment:
      - OLLAMA_API_URL=${OLLAMA_API_URL}
      - OLLAMA_MODEL_NAME=${OLLAMA_MODEL_NAME}
      - OLLAMA_TEMPERATURE=${OLLAMA_TEMPERATURE}
      - OLLAMA_CONTEXT_LENGTH=${OLLAMA_CONTEXT_LENGTH}
      - MAX_COMMANDS=${MAX_COMMANDS}
      - TIMEOUT_SECONDS=${TIMEOUT_SECONDS}
      - FLASK_PORT=${FLASK_PORT}
      - FLASK_HOST=${FLASK_HOST}